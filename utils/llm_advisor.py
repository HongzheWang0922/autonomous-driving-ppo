"""
LLMè®­ç»ƒé¡¾é—®æ¨¡å— - ä½¿ç”¨Gemini APIåˆ†æè®­ç»ƒè¿‡ç¨‹å¹¶æä¾›å»ºè®®
æ”¯æŒä»Stage 2å¼€å§‹ä½¿ç”¨ï¼Œå¯é€‰å¯ç”¨

åŠŸèƒ½ï¼š
- æ¯10000 episodeåˆ†æè®­ç»ƒç»Ÿè®¡æ•°æ®
- è¯†åˆ«è®­ç»ƒé—®é¢˜ï¼ˆå¦‚é—¯çº¢ç¯ã€ç¢°æ’é¢‘ç¹ç­‰ï¼‰
- æä¾›å¥–åŠ±å‡½æ•°å’Œè¶…å‚æ•°è°ƒæ•´å»ºè®®
- æ—¥å¿—ä¿å­˜åˆ°outputs/llm_logs/
"""

import os
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import numpy as np


class LLMTrainingAdvisor:
    """
    LLMè®­ç»ƒé¡¾é—®
    ä½¿ç”¨Gemini APIåˆ†æè®­ç»ƒæ•°æ®å¹¶æä¾›å»ºè®®
    """
    
    def __init__(
        self,
        api_key: str,
        stage: int,
        output_dir: str = "../outputs/llm_logs",
        call_frequency: int = 10000,  # æ¯10000 episodeè°ƒç”¨ä¸€æ¬¡
        max_calls_per_day: int = 200,
        enabled: bool = True,
    ):
        """
        Args:
            api_key: Gemini API Key
            stage: è®­ç»ƒé˜¶æ®µ (1-4)
            output_dir: æ—¥å¿—è¾“å‡ºç›®å½•
            call_frequency: è°ƒç”¨é¢‘ç‡ï¼ˆepisodeæ•°ï¼‰
            max_calls_per_day: æ¯å¤©æœ€å¤§è°ƒç”¨æ¬¡æ•°
            enabled: æ˜¯å¦å¯ç”¨
        """
        self.api_key = api_key
        self.stage = stage
        self.output_dir = Path(output_dir)
        self.call_frequency = call_frequency
        self.max_calls_per_day = max_calls_per_day
        self.enabled = enabled
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_calls = 0
        self.calls_today = 0
        self.last_call_date = None
        self.last_call_episode = 0
        
        # Episodeæ•°æ®ç¼“å­˜ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
        self.episode_data = []
        
        # åŠ è½½Google Generative AI
        if self.enabled:
            try:
                import google.generativeai as genai
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel('gemini-pro')
                print(f"LLMè®­ç»ƒé¡¾é—®å·²å¯ç”¨ (Gemini API)")
                print(f"   - Stage: {stage}")
                print(f"   - è°ƒç”¨é¢‘ç‡: æ¯{call_frequency} episode")
                print(f"   - æ—¥å¿—ç›®å½•: {output_dir}")
            except ImportError:
                print(f"è¯·å®‰è£… google-generativeai: pip install google-generativeai")
                self.enabled = False
            except Exception as e:
                print(f"åˆå§‹åŒ–Geminiå¤±è´¥: {e}")
                self.enabled = False
        else:
            print(f"LLMè®­ç»ƒé¡¾é—®æœªå¯ç”¨")
    
    def record_episode(self, info: Dict):
        """
        è®°å½•ä¸€ä¸ªepisodeçš„ä¿¡æ¯
        
        Args:
            info: episodeç»“æŸæ—¶çš„infoå­—å…¸
        """
        if not self.enabled:
            return
        
        # æå–å…³é”®ä¿¡æ¯
        episode_data = {
            "episode": info.get("episode", 0),
            "total_reward": info.get("total_reward", 0.0),
            "success": info.get("success", 0.0),
            "collision": int(info.get("collision", False)),
            "goal_reached": int(info.get("goal_reached", False)),
            "red_light_violations": info.get("red_light_violations", 0),
            "off_route_count": info.get("off_route_count", 0),
            "route_progress": info.get("route_progress", 0.0),
            "step": info.get("step", 0),
        }
        
        self.episode_data.append(episode_data)
        
        # ä¿æŒæœ€è¿‘1000ä¸ªepisode
        if len(self.episode_data) > 1000:
            self.episode_data = self.episode_data[-1000:]
    
    def should_call_llm(self, current_episode: int) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è°ƒç”¨LLM
        
        Args:
            current_episode: å½“å‰episodeæ•°
        
        Returns:
            æ˜¯å¦åº”è¯¥è°ƒç”¨
        """
        if not self.enabled:
            return False
        
        # æ£€æŸ¥è°ƒç”¨é¢‘ç‡
        if current_episode - self.last_call_episode < self.call_frequency:
            return False
        
        # æ£€æŸ¥æ¯æ—¥é™é¢
        today = datetime.now().date()
        if self.last_call_date != today:
            self.calls_today = 0
            self.last_call_date = today
        
        if self.calls_today >= self.max_calls_per_day:
            print(f"å·²è¾¾åˆ°ä»Šæ—¥LLMè°ƒç”¨ä¸Šé™ ({self.max_calls_per_day})")
            return False
        
        # è‡³å°‘éœ€è¦100ä¸ªepisodeçš„æ•°æ®
        if len(self.episode_data) < 100:
            return False
        
        return True
    
    def analyze_and_advise(self, current_episode: int, training_steps: int) -> Optional[Dict]:
        """
        åˆ†æè®­ç»ƒæ•°æ®å¹¶è·å–LLMå»ºè®®
        
        Args:
            current_episode: å½“å‰episodeæ•°
            training_steps: å½“å‰è®­ç»ƒæ­¥æ•°
        
        Returns:
            å»ºè®®å­—å…¸ï¼Œå¦‚æœæœªè°ƒç”¨åˆ™è¿”å›None
        """
        if not self.should_call_llm(current_episode):
            return None
        
        print(f"\n{'='*60}")
        print(f"ğŸ¤– è°ƒç”¨LLMè®­ç»ƒé¡¾é—® (Episode {current_episode})")
        print(f"{'='*60}\n")
        
        # å‡†å¤‡ç»Ÿè®¡æ•°æ®
        stats = self._compute_statistics()
        
        # ç”Ÿæˆæç¤ºè¯
        prompt = self._create_prompt(stats, current_episode, training_steps)
        
        # è°ƒç”¨LLM
        try:
            response = self._call_gemini(prompt)
            
            # è§£æå“åº”
            advice = {
                "episode": current_episode,
                "training_steps": training_steps,
                "timestamp": datetime.now().isoformat(),
                "statistics": stats,
                "llm_response": response,
            }
            
            # ä¿å­˜æ—¥å¿—
            self._save_log(advice)
            
            # æ›´æ–°è®¡æ•°
            self.total_calls += 1
            self.calls_today += 1
            self.last_call_episode = current_episode
            
            # æ‰“å°å»ºè®®
            self._print_advice(advice)
            
            return advice
        
        except Exception as e:
            print(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _compute_statistics(self) -> Dict:
        """è®¡ç®—æœ€è¿‘1000ä¸ªepisodeçš„ç»Ÿè®¡æ•°æ®"""
        if not self.episode_data:
            return {}
        
        data = self.episode_data[-1000:]  # æœ€è¿‘1000ä¸ª
        
        rewards = [d["total_reward"] for d in data]
        successes = [d["success"] for d in data]
        
        stats = {
            "num_episodes": len(data),
            "success_rate": np.mean([d["goal_reached"] for d in data]) * 100,
            "collision_rate": np.mean([d["collision"] for d in data]) * 100,
            "mean_reward": np.mean(rewards),
            "std_reward": np.std(rewards),
            "min_reward": np.min(rewards),
            "max_reward": np.max(rewards),
            "mean_progress": np.mean([d["route_progress"] for d in data]) * 100,
            "mean_steps": np.mean([d["step"] for d in data]),
        }
        
        # Stageç‰¹å®šç»Ÿè®¡
        if self.stage >= 2:
            total_violations = sum([d["red_light_violations"] for d in data])
            stats["red_light_violations_total"] = total_violations
            stats["red_light_violations_per_episode"] = total_violations / len(data)
        
        if self.stage >= 3:
            stats["off_route_rate"] = np.mean([d["off_route_count"] > 0 for d in data]) * 100
        
        return stats
    
    def _create_prompt(self, stats: Dict, episode: int, training_steps: int) -> str:
        """åˆ›å»ºå‘é€ç»™LLMçš„æç¤ºè¯"""
        
        # Stageæè¿°
        stage_descriptions = {
            1: "Stage 1: ç©ºè·¯å¯¼èˆª - å­¦ä¹ ä¸åç¦»è½¦é“ã€æˆåŠŸåˆ°è¾¾ç»ˆç‚¹ï¼ˆæ— å…¶ä»–è½¦è¾†ï¼‰",
            2: "Stage 2: çº¢ç»¿ç¯éµå®ˆ - å­¦ä¹ éµå®ˆäº¤é€šä¿¡å·ï¼ˆæ— å…¶ä»–è½¦è¾†ï¼‰",
            3: "Stage 3: åŠ¨æ€é¿éšœ - å­¦ä¹ ä¸å…¶ä»–è½¦è¾†äº¤äº’å’Œé¿éšœ",
            4: "Stage 4: ç»¼åˆåœºæ™¯ - è¡Œäºº + é•¿è·ç¦»å¯¼èˆª + å¤æ‚äº¤é€š",
        }
        
        prompt = f"""ä½ æ˜¯ä¸€ä½å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸“å®¶ï¼Œæ­£åœ¨å¸®åŠ©è®­ç»ƒä¸€ä¸ªè‡ªåŠ¨é©¾é©¶PPO Agentã€‚

## å½“å‰è®­ç»ƒé˜¶æ®µ
{stage_descriptions.get(self.stage, "æœªçŸ¥é˜¶æ®µ")}

## è®­ç»ƒè¿›åº¦
- å½“å‰Episode: {episode:,}
- è®­ç»ƒæ­¥æ•°: {training_steps:,}
- ç»Ÿè®¡çª—å£: æœ€è¿‘{stats.get('num_episodes', 0)}ä¸ªepisode

## è®­ç»ƒç»Ÿè®¡ (æœ€è¿‘{stats.get('num_episodes', 0)}ä¸ªepisode)

### æˆåŠŸç‡æŒ‡æ ‡
- æˆåŠŸç‡ (åˆ°è¾¾ç»ˆç‚¹): {stats.get('success_rate', 0):.1f}%
- ç¢°æ’ç‡: {stats.get('collision_rate', 0):.1f}%
- å¹³å‡è·¯ç”±å®Œæˆåº¦: {stats.get('mean_progress', 0):.1f}%

### å¥–åŠ±æŒ‡æ ‡
- å¹³å‡Reward: {stats.get('mean_reward', 0):.2f}
- Rewardæ ‡å‡†å·®: {stats.get('std_reward', 0):.2f}
- RewardèŒƒå›´: [{stats.get('min_reward', 0):.2f}, {stats.get('max_reward', 0):.2f}]

### è¡Œä¸ºæŒ‡æ ‡
- å¹³å‡Episodeé•¿åº¦: {stats.get('mean_steps', 0):.1f} æ­¥
"""
        
        # æ·»åŠ Stageç‰¹å®šæŒ‡æ ‡
        if self.stage >= 2:
            prompt += f"""
### çº¢ç»¿ç¯éµå®ˆ
- æ€»é—¯çº¢ç¯æ¬¡æ•°: {stats.get('red_light_violations_total', 0)}
- å¹³å‡æ¯episodeé—¯çº¢ç¯: {stats.get('red_light_violations_per_episode', 0):.2f}æ¬¡
"""
        
        if self.stage >= 3:
            prompt += f"""
### è·¯ç”±éµå®ˆ
- åç¦»è·¯ç”±æ¯”ä¾‹: {stats.get('off_route_rate', 0):.1f}%
"""
        
        prompt += """

## è¯·æä¾›åˆ†æå’Œå»ºè®®

è¯·åˆ†æä»¥ä¸Šæ•°æ®ï¼Œå¹¶æä¾›ï¼š

1. **é—®é¢˜è¯Šæ–­**: å½“å‰è®­ç»ƒçš„ä¸»è¦é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆå¦‚ï¼šæˆåŠŸç‡ä½ã€é—¯çº¢ç¯é¢‘ç¹ã€ç¢°æ’ç‡é«˜ç­‰ï¼‰

2. **å¥–åŠ±å‡½æ•°è°ƒæ•´å»ºè®®**: 
   - å“ªäº›å¥–åŠ±æƒé‡éœ€è¦è°ƒæ•´ï¼Ÿ
   - æ˜¯å¦éœ€è¦å¢åŠ æ–°çš„å¥–åŠ±é¡¹ï¼Ÿ
   - å»ºè®®çš„å…·ä½“æ•°å€¼ï¼ˆå¦‚ï¼šå°†çº¢ç»¿ç¯è¿è§„æƒ©ç½šä»-5è°ƒæ•´åˆ°-10ï¼‰

3. **è¶…å‚æ•°è°ƒæ•´å»ºè®®**:
   - å­¦ä¹ ç‡æ˜¯å¦éœ€è¦è°ƒæ•´ï¼Ÿ
   - å…¶ä»–PPOè¶…å‚æ•°å»ºè®®ï¼ˆå¦‚entropy coefficient, clip rangeç­‰ï¼‰

4. **è®­ç»ƒç­–ç•¥å»ºè®®**:
   - æ˜¯å¦éœ€è¦å¢åŠ /å‡å°‘episodeé•¿åº¦ï¼Ÿ
   - æ˜¯å¦éœ€è¦è°ƒæ•´ç¯å¢ƒéš¾åº¦ï¼Ÿ

è¯·ç›´æ¥ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ï¼Œé¿å…æ¨¡ç³Šçš„æè¿°ã€‚
"""
        
        return prompt
    
    def _call_gemini(self, prompt: str) -> str:
        """è°ƒç”¨Gemini API"""
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
    
    def _save_log(self, advice: Dict):
        """ä¿å­˜å»ºè®®æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = self.output_dir / f"stage{self.stage}_episode{advice['episode']}_{timestamp}.json"
        
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(advice, f, indent=2, ensure_ascii=False)
            print(f"æ—¥å¿—å·²ä¿å­˜: {log_file}")
        except Exception as e:
            print(f"ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")
    
    def _print_advice(self, advice: Dict):
        """æ‰“å°å»ºè®®åˆ°æ§åˆ¶å°"""
        print(f"\n{'ğŸ¤–'*30}")
        print(f"LLMè®­ç»ƒé¡¾é—®å»ºè®® (Episode {advice['episode']})")
        print(f"{'ğŸ¤–'*30}\n")
        print(advice['llm_response'])
        print(f"\n{'='*60}\n")
    
    def get_summary(self) -> str:
        """è·å–ä½¿ç”¨æ‘˜è¦"""
        return f"""
LLMè®­ç»ƒé¡¾é—®ä½¿ç”¨æ‘˜è¦:
- æ€»è°ƒç”¨æ¬¡æ•°: {self.total_calls}
- ä»Šæ—¥è°ƒç”¨æ¬¡æ•°: {self.calls_today}
- æœ€åè°ƒç”¨episode: {self.last_call_episode}
- æ—¥å¿—ç›®å½•: {self.output_dir}
"""


def create_llm_advisor(
    stage: int,
    api_key: Optional[str] = None,
    enabled: bool = False,
    **kwargs
) -> Optional[LLMTrainingAdvisor]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºLLMè®­ç»ƒé¡¾é—®
    
    Args:
        stage: è®­ç»ƒé˜¶æ®µ
        api_key: Gemini API Key
        enabled: æ˜¯å¦å¯ç”¨
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        LLMTrainingAdvisorå®ä¾‹ï¼Œå¦‚æœæœªå¯ç”¨åˆ™è¿”å›None
    """
    # Stage 1ä¸ä½¿ç”¨LLMé¡¾é—®
    if stage == 1:
        print("Stage 1 ä¸ä½¿ç”¨LLMè®­ç»ƒé¡¾é—®")
        return None
    
    # å¦‚æœæœªå¯ç”¨ï¼Œè¿”å›None
    if not enabled:
        print("LLMè®­ç»ƒé¡¾é—®æœªå¯ç”¨")
        return None
    
    # æ£€æŸ¥API Key
    if not api_key:
        print("æœªæä¾›Gemini API Keyï¼ŒLLMè®­ç»ƒé¡¾é—®æœªå¯ç”¨")
        print("   ä½¿ç”¨ --llm --llm-api-key YOUR_KEY å¯ç”¨")
        return None
    
    try:
        advisor = LLMTrainingAdvisor(
            api_key=api_key,
            stage=stage,
            enabled=True,
            **kwargs
        )
        return advisor
    except Exception as e:
        print(f"åˆ›å»ºLLMè®­ç»ƒé¡¾é—®å¤±è´¥: {e}")
        return None


# ç”¨äºæµ‹è¯•
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•LLMè®­ç»ƒé¡¾é—®')
    parser.add_argument('--api-key', type=str, required=True, help='Gemini API Key')
    parser.add_argument('--stage', type=int, default=2, help='è®­ç»ƒé˜¶æ®µ')
    args = parser.parse_args()
    
    print("æµ‹è¯•LLMè®­ç»ƒé¡¾é—®...\n")
    
    # åˆ›å»ºé¡¾é—®
    advisor = LLMTrainingAdvisor(
        api_key=args.api_key,
        stage=args.stage,
        enabled=True
    )
    
    # æ¨¡æ‹Ÿä¸€äº›episodeæ•°æ®
    print("ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    for i in range(100):
        fake_info = {
            "episode": i,
            "total_reward": np.random.normal(50, 20),
            "success": np.random.random(),
            "collision": np.random.random() < 0.2,
            "goal_reached": np.random.random() < 0.6,
            "red_light_violations": np.random.randint(0, 3),
            "off_route_count": np.random.randint(0, 5),
            "route_progress": np.random.uniform(0.5, 1.0),
            "step": np.random.randint(100, 500),
        }
        advisor.record_episode(fake_info)
    
    # å¼ºåˆ¶è°ƒç”¨LLM
    print("\nè°ƒç”¨LLMåˆ†æ...")
    advisor.last_call_episode = -10000  # å¼ºåˆ¶è§¦å‘
    advice = advisor.analyze_and_advise(current_episode=100, training_steps=50000)
    
    if advice:
        print("\næµ‹è¯•æˆåŠŸï¼")
        print(advisor.get_summary())
    else:
        print("\næµ‹è¯•å¤±è´¥")


